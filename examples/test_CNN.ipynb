{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a548746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# 3D U-Net for CellMap multi-class segmentation (crop-based KFold)\n",
    "# Input channels: Raw + Gaussian(sigma=2)  (recommended for 3D U-Net)\n",
    "# Labels: background(0) + 5 classes (1..5)\n",
    "# Data loading aligned with your .zattrs method\n",
    "# =============================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import zarr  # type: ignore\n",
    "from tqdm import tqdm  # type: ignore\n",
    "from scipy.ndimage import gaussian_filter, sobel  # type: ignore\n",
    "\n",
    "from sklearn.model_selection import KFold  # type: ignore\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1be9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Crops\n",
    "CROP_IDS = [\"crop292\"]\n",
    "# CROP_IDS = [\"crop292\", \"crop234\", \"crop236\", \"crop237\", \"crop239\"]\n",
    "\n",
    "RAW_S0 = r\"../data/jrc_cos7-1a/jrc_cos7-1a.zarr/recon-1/em/fibsem-uint8/s0\"\n",
    "GROUNDTRUTH_ROOT = r\"../data/jrc_cos7-1a/jrc_cos7-1a.zarr/recon-1/labels/groundtruth\"\n",
    "\n",
    "SELECT_CLASSES = {\n",
    "    \"cyto\": 35,\n",
    "    \"mito_mem\": 3,\n",
    "    \"mito_lum\": 4,\n",
    "    \"er_mem\": 16,\n",
    "    \"er_lum\": 17,\n",
    "}\n",
    "\n",
    "CLASS_ID_MAP = {\n",
    "    \"cyto\": 1,\n",
    "    \"mito_mem\": 2,\n",
    "    \"mito_lum\": 3,\n",
    "    \"er_mem\": 4,\n",
    "    \"er_lum\": 5,\n",
    "}\n",
    "\n",
    "CLASS_NAMES = [\"bg\", \"cyto\", \"mito_mem\", \"mito_lum\", \"er_mem\", \"er_lum\"]\n",
    "NUM_CLASSES = 6  # 0..5\n",
    "\n",
    "REF_CLASS = \"nucpl\"\n",
    "\n",
    "# Training\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 2\n",
    "LR = 2e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# Patch sampling (adjust to your GPU memory)\n",
    "PATCH_ZYX = (32, 128, 128)  # (Z,Y,X)\n",
    "PATCHES_PER_EPOCH = 300     # per fold\n",
    "VAL_PATCHES = 80\n",
    "\n",
    "# Sliding-window inference for full volume evaluation\n",
    "INFER_STRIDE = (16, 64, 64)  # overlap = patch - stride\n",
    "\n",
    "# Output\n",
    "OUT_DIR = \"../Result/unet3d_runs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba5fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Feature extraction for CNN\n",
    "# Recommended for 3D U-Net: 2 channels = [raw, gauss(s=2)]\n",
    "# (Optional 3rd channel = gradmag2 if you want)\n",
    "# -----------------------------\n",
    "USE_GRADMAG2_AS_3RD_CH = False\n",
    "\n",
    "def make_cnn_input(raw_uint8_zyx: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Input: raw uint8 (Z,Y,X)\n",
    "    Output: float32 (C,Z,Y,X)\n",
    "      C=2 or 3\n",
    "    \"\"\"\n",
    "    img = raw_uint8_zyx.astype(np.float32) / 255.0  # raw\n",
    "    g2 = gaussian_filter(img, sigma=2.0)\n",
    "\n",
    "    if not USE_GRADMAG2_AS_3RD_CH:\n",
    "        x = np.stack([img, g2], axis=0).astype(np.float32)\n",
    "        return x\n",
    "\n",
    "    # Optional: GradMag on g2 (XY only)\n",
    "    gx = sobel(g2, axis=2)\n",
    "    gy = sobel(g2, axis=1)\n",
    "    gradmag2 = np.sqrt(gx * gx + gy * gy)\n",
    "    x = np.stack([img, g2, gradmag2], axis=0).astype(np.float32)\n",
    "    return x\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Data loading (aligned to your method)\n",
    "# -----------------------------\n",
    "def load_one_crop(crop_id: str, raw_zarr) -> dict:\n",
    "    \"\"\"\n",
    "    Returns dict:\n",
    "      raw: uint8 (Z,Y,X)\n",
    "      label: uint8 (Z,Y,X) 0..5\n",
    "      id: str\n",
    "      shape: (Z,Y,X)\n",
    "    \"\"\"\n",
    "    crop_root = os.path.join(GROUNDTRUTH_ROOT, crop_id)\n",
    "    ref_s0 = os.path.join(crop_root, REF_CLASS, \"s0\")\n",
    "    ref_zattr = os.path.join(crop_root, REF_CLASS, \".zattrs\")\n",
    "\n",
    "    ref_arr = zarr.open(ref_s0, mode=\"r\")\n",
    "    Dz, Dy, Dx = ref_arr.shape\n",
    "\n",
    "    with open(ref_zattr, \"r\") as f:\n",
    "        attrs = json.load(f)\n",
    "    ms = attrs[\"multiscales\"][0][\"datasets\"][0]\n",
    "    scale = ms[\"coordinateTransformations\"][0][\"scale\"]\n",
    "    trans = ms[\"coordinateTransformations\"][1][\"translation\"]\n",
    "    scale_z, scale_y, scale_x = scale\n",
    "    tz, ty, tx = trans\n",
    "\n",
    "    vz0 = int(tz / scale_z)\n",
    "    vy0 = int(ty / scale_y)\n",
    "    vx0 = int(tx / scale_x)\n",
    "    vz1, vy1, vx1 = vz0 + Dz, vy0 + Dy, vx0 + Dx\n",
    "\n",
    "    raw_crop = raw_zarr[vz0:vz1, vy0:vy1, vx0:vx1]  # uint8 (Z,Y,X)\n",
    "\n",
    "    # Build multi-class label\n",
    "    label_multi = np.zeros((Dz, Dy, Dx), dtype=np.uint8)\n",
    "    for cname in SELECT_CLASSES.keys():\n",
    "        path = os.path.join(crop_root, cname, \"s0\")\n",
    "        try:\n",
    "            arr = zarr.open(path, mode=\"r\")[:]  # binary mask\n",
    "            cid = CLASS_ID_MAP[cname]\n",
    "            label_multi[arr > 0] = cid\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: failed load class {cname} in {crop_id}: {e}\")\n",
    "\n",
    "    return {\"raw\": raw_crop, \"label\": label_multi, \"shape\": (Dz, Dy, Dx), \"id\": crop_id}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f4e0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Patch sampler dataset\n",
    "# -----------------------------\n",
    "class RandomPatchDataset(Dataset):\n",
    "    def __init__(self, crops: list[dict], n_patches: int, patch_zyx=(32,128,128)):\n",
    "        self.crops = crops\n",
    "        self.n_patches = n_patches\n",
    "        self.pz, self.py, self.px = patch_zyx\n",
    "\n",
    "        # Precompute per-crop valid ranges\n",
    "        self.ranges = []\n",
    "        for c in self.crops:\n",
    "            Dz, Dy, Dx = c[\"shape\"]\n",
    "            assert Dz >= self.pz and Dy >= self.py and Dx >= self.px, f\"Crop too small: {c['id']}\"\n",
    "            self.ranges.append((Dz - self.pz, Dy - self.py, Dx - self.px))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_patches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # pick a crop\n",
    "        ci = np.random.randint(0, len(self.crops))\n",
    "        crop = self.crops[ci]\n",
    "        Dz_off, Dy_off, Dx_off = self.ranges[ci]\n",
    "\n",
    "        z0 = np.random.randint(0, Dz_off + 1)\n",
    "        y0 = np.random.randint(0, Dy_off + 1)\n",
    "        x0 = np.random.randint(0, Dx_off + 1)\n",
    "\n",
    "        raw_patch = crop[\"raw\"][z0:z0+self.pz, y0:y0+self.py, x0:x0+self.px]\n",
    "        y_patch = crop[\"label\"][z0:z0+self.pz, y0:y0+self.py, x0:x0+self.px]\n",
    "\n",
    "        x_patch = make_cnn_input(raw_patch)  # (C,Z,Y,X)\n",
    "\n",
    "        # torch\n",
    "        x = torch.from_numpy(x_patch)                      # float32\n",
    "        y = torch.from_numpy(y_patch.astype(np.int64))     # long (Z,Y,X)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee9164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3D U-Net (small & clean)\n",
    "# -----------------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.InstanceNorm3d(out_ch),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.InstanceNorm3d(out_ch),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_ch, n_classes, base=32):\n",
    "        super().__init__()\n",
    "        self.enc1 = DoubleConv(in_ch, base)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "\n",
    "        self.enc2 = DoubleConv(base, base*2)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "\n",
    "        self.enc3 = DoubleConv(base*2, base*4)\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "\n",
    "        self.bott = DoubleConv(base*4, base*8)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose3d(base*8, base*4, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(base*8, base*4)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose3d(base*4, base*2, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(base*4, base*2)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose3d(base*2, base, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(base*2, base)\n",
    "\n",
    "        self.out = nn.Conv3d(base, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        b  = self.bott(self.pool3(e3))\n",
    "\n",
    "        d3 = self.up3(b)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        return self.out(d1)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Loss: CE + Soft Dice (multi-class)\n",
    "# -----------------------------\n",
    "def soft_dice_loss(logits, targets, num_classes=6, eps=1e-6):\n",
    "    \"\"\"\n",
    "    logits: (B,C,Z,Y,X)\n",
    "    targets: (B,Z,Y,X) int\n",
    "    \"\"\"\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    onehot = F.one_hot(targets, num_classes=num_classes).permute(0,4,1,2,3).float()\n",
    "\n",
    "    dims = (0,2,3,4)\n",
    "    inter = torch.sum(probs * onehot, dims)\n",
    "    denom = torch.sum(probs + onehot, dims)\n",
    "    dice = (2*inter + eps) / (denom + eps)\n",
    "\n",
    "    # ignore background? (optional) — here we include all; you can drop bg by dice[1:]\n",
    "    loss = 1.0 - dice.mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics (Dice per class)\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def dice_per_class(pred, gt, num_classes=6, eps=1e-6):\n",
    "    \"\"\"\n",
    "    pred, gt: (Z,Y,X) int (cpu numpy or torch)\n",
    "    returns: list length num_classes\n",
    "    \"\"\"\n",
    "    if isinstance(pred, torch.Tensor):\n",
    "        pred = pred.cpu().numpy()\n",
    "    if isinstance(gt, torch.Tensor):\n",
    "        gt = gt.cpu().numpy()\n",
    "\n",
    "    out = []\n",
    "    for c in range(num_classes):\n",
    "        p = (pred == c)\n",
    "        g = (gt == c)\n",
    "        inter = (p & g).sum()\n",
    "        denom = p.sum() + g.sum()\n",
    "        out.append((2*inter + eps) / (denom + eps))\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Sliding-window inference\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def sliding_window_predict(model, raw_zyx: np.ndarray, patch_zyx=(32,128,128), stride_zyx=(16,64,64)):\n",
    "    \"\"\"\n",
    "    raw_zyx: uint8 (Z,Y,X)\n",
    "    returns: pred (Z,Y,X) uint8\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    C = 3 if USE_GRADMAG2_AS_3RD_CH else 2\n",
    "\n",
    "    pz, py, px = patch_zyx\n",
    "    sz, sy, sx = stride_zyx\n",
    "    Dz, Dy, Dx = raw_zyx.shape\n",
    "\n",
    "    # score accumulation\n",
    "    scores = np.zeros((NUM_CLASSES, Dz, Dy, Dx), dtype=np.float32)\n",
    "    counts = np.zeros((Dz, Dy, Dx), dtype=np.float32)\n",
    "\n",
    "    z_starts = list(range(0, max(Dz - pz, 0) + 1, sz))\n",
    "    y_starts = list(range(0, max(Dy - py, 0) + 1, sy))\n",
    "    x_starts = list(range(0, max(Dx - px, 0) + 1, sx))\n",
    "    if z_starts[-1] != Dz - pz: z_starts.append(Dz - pz)\n",
    "    if y_starts[-1] != Dy - py: y_starts.append(Dy - py)\n",
    "    if x_starts[-1] != Dx - px: x_starts.append(Dx - px)\n",
    "\n",
    "    for z0 in tqdm(z_starts, desc=\"Infer z\"):\n",
    "        for y0 in y_starts:\n",
    "            for x0 in x_starts:\n",
    "                patch_raw = raw_zyx[z0:z0+pz, y0:y0+py, x0:x0+px]\n",
    "                x_patch = make_cnn_input(patch_raw)  # (C,Z,Y,X)\n",
    "                x = torch.from_numpy(x_patch).unsqueeze(0).to(DEVICE)  # (1,C,Z,Y,X)\n",
    "\n",
    "                logits = model(x)\n",
    "                prob = torch.softmax(logits, dim=1).squeeze(0).cpu().numpy()  # (K,Z,Y,X)\n",
    "\n",
    "                scores[:, z0:z0+pz, y0:y0+py, x0:x0+px] += prob\n",
    "                counts[z0:z0+pz, y0:y0+py, x0:x0+px] += 1.0\n",
    "\n",
    "    scores /= np.maximum(counts[None, ...], 1e-6)\n",
    "    pred = np.argmax(scores, axis=0).astype(np.uint8)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fb1574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Train one fold\n",
    "# -----------------------------\n",
    "def train_one_fold(fold_id, train_crops, val_crops):\n",
    "    run_dir = os.path.join(OUT_DIR, f\"fold_{fold_id}\")\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    in_ch = 3 if USE_GRADMAG2_AS_3RD_CH else 2\n",
    "    model = UNet3D(in_ch=in_ch, n_classes=NUM_CLASSES, base=32).to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_ds = RandomPatchDataset(train_crops, n_patches=PATCHES_PER_EPOCH, patch_zyx=PATCH_ZYX)\n",
    "    val_ds   = RandomPatchDataset(val_crops, n_patches=VAL_PATCHES, patch_zyx=PATCH_ZYX)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "    best_val = 1e9\n",
    "    best_path = os.path.join(run_dir, \"best.pt\")\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        t0 = time.time()\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "\n",
    "        for x, y in tqdm(train_loader, desc=f\"[Fold {fold_id}] Train epoch {epoch}\", leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = 0.5 * ce(logits, y) + 0.5 * soft_dice_loss(logits, y, num_classes=NUM_CLASSES)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "        tr_loss /= max(len(train_loader), 1)\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        va_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(val_loader, desc=f\"[Fold {fold_id}] Val epoch {epoch}\", leave=False):\n",
    "                x = x.to(DEVICE)\n",
    "                y = y.to(DEVICE)\n",
    "                logits = model(x)\n",
    "                loss = 0.5 * ce(logits, y) + 0.5 * soft_dice_loss(logits, y, num_classes=NUM_CLASSES)\n",
    "                va_loss += loss.item()\n",
    "        va_loss /= max(len(val_loader), 1)\n",
    "\n",
    "        dt = time.time() - t0\n",
    "        print(f\"[Fold {fold_id}] Epoch {epoch:02d} | train={tr_loss:.4f} val={va_loss:.4f} | {dt/60:.2f} min\")\n",
    "\n",
    "        # save best\n",
    "        if va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            torch.save({\"model\": model.state_dict(), \"in_ch\": in_ch}, best_path)\n",
    "\n",
    "    print(f\"[Fold {fold_id}] Best val loss: {best_val:.4f} saved to {best_path}\")\n",
    "\n",
    "    # Evaluate on full validation crop (first val crop only)\n",
    "    ckpt = torch.load(best_path, map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    model.eval()\n",
    "\n",
    "    val_crop = val_crops[0]\n",
    "    pred = sliding_window_predict(model, val_crop[\"raw\"], patch_zyx=PATCH_ZYX, stride_zyx=INFER_STRIDE)\n",
    "\n",
    "    dices = dice_per_class(pred, val_crop[\"label\"], num_classes=NUM_CLASSES)\n",
    "    print(f\"[Fold {fold_id}] Full-volume Dice per class:\")\n",
    "    for ci, d in enumerate(dices):\n",
    "        print(f\"  {ci}:{CLASS_NAMES[ci]}  Dice={d:.4f}\")\n",
    "\n",
    "    # Save a few slice visualizations\n",
    "    vis_dir = os.path.join(run_dir, \"vis\")\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    Dz = val_crop[\"raw\"].shape[0]\n",
    "    zs = [Dz//4, Dz//2, (3*Dz)//4]\n",
    "\n",
    "    for z in zs:\n",
    "        fig = plt.figure(figsize=(18,6))\n",
    "        plt.subplot(1,3,1); plt.title(\"Raw\"); plt.imshow(val_crop[\"raw\"][z], cmap=\"gray\"); plt.axis(\"off\")\n",
    "        plt.subplot(1,3,2); plt.title(\"GT\");  plt.imshow(val_crop[\"label\"][z], cmap=\"tab10\", vmin=0, vmax=9); plt.axis(\"off\")\n",
    "        plt.subplot(1,3,3); plt.title(\"Pred\");plt.imshow(pred[z], cmap=\"tab10\", vmin=0, vmax=9); plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        outp = os.path.join(vis_dir, f\"val_{val_crop['id']}_z{z:04d}.png\")\n",
    "        plt.savefig(outp, dpi=200)\n",
    "        plt.close(fig)\n",
    "\n",
    "    return best_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e637bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 1. Open raw zarr\n",
    "    # ------------------------------------------------\n",
    "    raw_zarr = zarr.open(RAW_S0, mode=\"r\")\n",
    "    print(\"Raw shape:\", raw_zarr.shape)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 2. Load ONLY ONE crop (for debug)\n",
    "    # ------------------------------------------------\n",
    "    print(\"\\n===== Loading one crop for debug =====\")\n",
    "    all_crops = []\n",
    "\n",
    "    cid = CROP_IDS[0]   # 只用第一个 crop，例如 crop292\n",
    "    print(f\"Loading {cid} ...\")\n",
    "    crop = load_one_crop(cid, raw_zarr)\n",
    "    print(\"  shape:\", crop[\"shape\"], \"labels:\", np.unique(crop[\"label\"]))\n",
    "\n",
    "    all_crops.append(crop)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 3. Train & validate on the SAME crop (debug only)\n",
    "    # ------------------------------------------------\n",
    "    print(\"\\n===== DEBUG TRAIN (no KFold) =====\")\n",
    "\n",
    "    train_crops = all_crops\n",
    "    val_crops = all_crops\n",
    "\n",
    "    train_one_fold(\n",
    "        fold_id=0,\n",
    "        train_crops=train_crops,\n",
    "        val_crops=val_crops\n",
    "    )\n",
    "\n",
    "    print(\"\\n===== DEBUG RUN FINISHED =====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2781b47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "Raw shape: (1813, 4368, 20609)\n",
      "\n",
      "===== Loading one crop for debug =====\n",
      "Loading crop292 ...\n",
      "  shape: (400, 400, 400) labels: [0 1 2 3 4 5]\n",
      "\n",
      "===== DEBUG TRAIN (no KFold) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 1:   0%|          | 0/150 [00:00<?, ?it/s]/home/chwa386g/micromamba/envs/csc/lib/python3.11/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] Epoch 01 | train=1.1083 val=0.9969 | 36.70 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] Epoch 02 | train=0.9495 val=0.8697 | 35.51 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# def main():\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#     print(\"DEVICE:\", DEVICE)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     raw_zarr = zarr.open(RAW_S0, mode=\"r\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#     print(\"\\n===== Done =====\")\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m#     print(\"Fold best val losses:\", fold_losses)\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     28\u001b[39m train_crops = all_crops\n\u001b[32m     29\u001b[39m val_crops = all_crops\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mtrain_one_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_id\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_crops\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_crops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_crops\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_crops\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m===== DEBUG RUN FINISHED =====\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mtrain_one_fold\u001b[39m\u001b[34m(fold_id, train_crops, val_crops)\u001b[39m\n\u001b[32m     33\u001b[39m logits = model(x)\n\u001b[32m     34\u001b[39m loss = \u001b[32m0.5\u001b[39m * ce(logits, y) + \u001b[32m0.5\u001b[39m * soft_dice_loss(logits, y, num_classes=NUM_CLASSES)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m optimizer.step()\n\u001b[32m     38\u001b[39m tr_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/csc/lib/python3.11/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/csc/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/csc/lib/python3.11/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "#     print(\"DEVICE:\", DEVICE)\n",
    "#     raw_zarr = zarr.open(RAW_S0, mode=\"r\")\n",
    "#     print(\"Raw shape:\", raw_zarr.shape)\n",
    "\n",
    "#     # Load all crops into RAM (simple & robust; if OOM, we can stream per-epoch)\n",
    "#     all_crops = []\n",
    "#     print(\"\\n===== Loading crops =====\")\n",
    "#     for cid in CROP_IDS:\n",
    "#         print(f\"Loading {cid}...\")\n",
    "#         c = load_one_crop(cid, raw_zarr)\n",
    "#         print(\"  shape:\", c[\"shape\"], \"labels:\", np.unique(c[\"label\"]))\n",
    "#         all_crops.append(c)\n",
    "\n",
    "#     # KFold on crop index\n",
    "#     crop_indices = np.arange(len(all_crops))\n",
    "#     kf = KFold(n_splits=len(all_crops), shuffle=True, random_state=SEED)\n",
    "\n",
    "#     fold_losses = []\n",
    "#     for fold_id, (tr_idx, va_idx) in enumerate(kf.split(crop_indices)):\n",
    "#         train_crops = [all_crops[i] for i in tr_idx]\n",
    "#         val_crops   = [all_crops[i] for i in va_idx]  # single crop\n",
    "\n",
    "#         print(\"\\n\" + \"=\"*60)\n",
    "#         print(f\"FOLD {fold_id} | train={[c['id'] for c in train_crops]} | val={[c['id'] for c in val_crops]}\")\n",
    "#         loss = train_one_fold(fold_id, train_crops, val_crops)\n",
    "#         fold_losses.append(loss)\n",
    "\n",
    "#     print(\"\\n===== Done =====\")\n",
    "#     print(\"Fold best val losses:\", fold_losses)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf30303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
